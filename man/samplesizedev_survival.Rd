% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/samplesizedev_survival.R
\name{samplesizedev_survival}
\alias{samplesizedev_survival}
\title{Sample size required to develop a risk prediction model for Survival outcomes}
\usage{
samplesizedev_survival(
  S,
  p,
  c,
  n.predictors,
  beta = beta,
  nval = 25000,
  nsim = 1000,
  parallel = TRUE
)
}
\arguments{
\item{S}{(numeric) The target expected calibration slope}

\item{p}{(numeric) The anticipated proportion of events (at the time-point of interest)}

\item{c}{(numeric) The anticipated C-index}

\item{n.predictors}{(numeric) The number of candidate predictor variables}

\item{beta}{(numeric) The relative strength of predictors (0 for noise)}

\item{nval}{(numeric) Size of validation data (at least 10000 )}

\item{nsim}{(numeric) The number of simulations (at least 500, default value 1000 to ensure small simulation error)}

\item{parallel}{(logical) parallel processing to speed up computations (default=TRUE)}
}
\value{
n: the required sample size
}
\description{
This function calculates the sample size required to achieve an expected Calibration Slope (S), given anticipated features of the data and the model
(proportion of events (uncensored observations) at a given time point of interest, C-index and number of predictors).

It takes approximately one minute to run. Ideally it should be followed by checking also
the Mean Absolute Prediction Error that corresponds to the calculated sample size.
}
\examples{
# Find the sample size
# samplesizedev_survival(S = 0.9, p = 0.2, c = 0.85, n.predictors = 10,  nsim = 500, parallel = FALSE)

# Prefer parallel computing with >2 cores that ensure faster running
# samplesizedev_survival(S = 0.9, p = 0.2, c = 0.85, n.predictors = 10,  nsim = 1000, parallel = TRUE)

# Check the expected MAPE and Calibration Slope for the selected size
# expected_cs_survival(n = 530, p = 0.2, c = 0.85, n.predictors = 10, nsim = 1000, parallel = TRUE)



}
\seealso{
expected_cs_mape_binary
}
